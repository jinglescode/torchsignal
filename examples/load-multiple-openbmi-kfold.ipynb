{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/Users/jingles/github/torchsignal\n"
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsignal.datasets import OPENBMI\n",
    "from torchsignal.filter.channels import pick_channels\n",
    "from torchsignal.filter.butterworth import butter_bandpass_filter\n",
    "from torchsignal.transform.segment import segment_signal\n",
    "from torchsignal.datasets.utils import onehot_targets\n",
    "from torchsignal.datasets.dataset import PyTorchDataset\n",
    "from torchsignal.datasets.utils import train_test_split\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"_data/openbmi\"\n",
    "num_class = 4\n",
    "sample_rate = 1000\n",
    "subject_ids = [1]\n",
    "sessions = [1]\n",
    "selected_channels = ['P7', 'P3', 'Pz', 'P4', 'P8', 'PO9', 'O1', 'Oz', 'O2', 'PO10']\n",
    "bandpass = {\n",
    "    'low': 6,\n",
    "    'high': 15,\n",
    "    'order': 6,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(subject_dataset):\n",
    "    \n",
    "    # filter channels\n",
    "    data_selected_channels = pick_channels(data=subject_dataset.data, channel_names=subject_dataset.channel_names, selected_channels=selected_channels)\n",
    "\n",
    "    # selects the first segment (first 1-second), discard the rest\n",
    "    data_segmented_full = segment_signal(\n",
    "        signal=data_selected_channels,\n",
    "        window_len=1,\n",
    "        shift_len=1000,\n",
    "        sample_rate=1000,\n",
    "        add_segment_axis=True,\n",
    "    )\n",
    "\n",
    "    data_segmented = np.zeros((data_segmented_full.shape[0], data_segmented_full.shape[1], data_segmented_full.shape[3]))\n",
    "\n",
    "    for trial in range(0, data_segmented_full.shape[0]):\n",
    "        for channel in range(0, data_segmented_full.shape[1]):\n",
    "            data_segmented[trial, channel, :] = data_segmented_full[trial, channel, 0, :]\n",
    "\n",
    "    # filter by bandpass\n",
    "    data_filtered = butter_bandpass_filter(data_segmented, lowcut=6, highcut=15, sample_rate=1000, order=6)\n",
    "\n",
    "    # one-hot targets\n",
    "    targets_onehot = onehot_targets(subject_dataset.targets, num_class=4)\n",
    "\n",
    "    subject_dataset.set_data_targets(data=data_filtered, targets=targets_onehot)\n",
    "\n",
    "    return subject_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_multiple(subject_ids: [], sessions: [], verbose: bool = False) -> None:\n",
    "    data_by_subjects = {}\n",
    "\n",
    "    for subject_id in subject_ids:\n",
    "        print('Load subject:', subject_id)\n",
    "        subject_data = None\n",
    "        subject_target = None\n",
    "\n",
    "        for session in sessions:\n",
    "            subject_dataset = OPENBMI(root=\"_data/openbmi\", subject_id=subject_id, session=session)\n",
    "\n",
    "            if subject_data is None: # if its session #1, will be None\n",
    "                subject_data = np.zeros((0, subject_dataset.data.shape[1], subject_dataset.data.shape[2]))\n",
    "                subject_target = np.zeros((0, ))\n",
    "\n",
    "            subject_data = np.concatenate((subject_data, subject_dataset.data))\n",
    "            subject_target = np.concatenate((subject_target, subject_dataset.targets))\n",
    "\n",
    "        data_by_subjects[subject_id] = PyTorchDataset(data=subject_data, targets=subject_target)\n",
    "    \n",
    "    return data_by_subjects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Load subject: 1\nLoad subject: 2\n"
    }
   ],
   "source": [
    "data_by_subjects = load_multiple(subject_ids, sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_dataset(data_by_subjects):\n",
    "    train_dataset_by_subjects = {}\n",
    "    test_dataset_by_subjects = {}\n",
    "\n",
    "    for subject_id in list(data_by_subjects.keys()):\n",
    "        train_dataset, test_dataset = train_test_split(data_by_subjects[subject_id].data, data_by_subjects[subject_id].targets)\n",
    "        \n",
    "        train_dataset_by_subjects[subject_id] = train_dataset\n",
    "        test_dataset_by_subjects[subject_id] = test_dataset\n",
    "    \n",
    "    return train_dataset_by_subjects, test_dataset_by_subjects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_by_subjects, test_dataset_by_subjects = train_test_dataset(data_by_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(75, 62, 4000)"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "\n",
    "\n",
    "subject_dataset = process_data(subject_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torchsignal.datasets.dataset.PyTorchDataset"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "type(data_by_subjects[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_subject_out(data_by_subjects, selected_subject_id=1):\n",
    "    train_dataset = None\n",
    "    val_dataset = None\n",
    "    test_dataset = None\n",
    "\n",
    "    assert selected_subject_id in data_by_subjects, \"Must select subjects in dataset\"\n",
    "\n",
    "    # selected subject\n",
    "    test_dataset = data_by_subjects[selected_subject_id]\n",
    "\n",
    "    # the rest\n",
    "    other_subjects_x_train = []\n",
    "    other_subjects_y_train = []\n",
    "    other_subjects_x_val = []\n",
    "    other_subjects_y_val = []\n",
    "\n",
    "    for subject_id in list(data_by_subjects.keys()):\n",
    "        if subject_id != selected_subject_id:\n",
    "\n",
    "            train_dataset, val_dataset = train_test_split(data_by_subjects[subject_id].data, data_by_subjects[subject_id].targets)\n",
    "            \n",
    "            other_subjects_x_train.extend(train_dataset.data)\n",
    "            other_subjects_y_train.extend(train_dataset.targets)\n",
    "            other_subjects_x_val.extend(val_dataset.data)\n",
    "            other_subjects_y_val.extend(val_dataset.targets)\n",
    "\n",
    "    other_subjects_x_train = np.array(other_subjects_x_train)\n",
    "    other_subjects_y_train = np.array(other_subjects_y_train)\n",
    "    other_subjects_x_val = np.array(other_subjects_x_val)\n",
    "    other_subjects_y_val = np.array(other_subjects_y_val)\n",
    "\n",
    "    train_dataset = PyTorchDataset(other_subjects_x_train, other_subjects_y_train)\n",
    "    val_dataset = PyTorchDataset(other_subjects_x_val, other_subjects_y_val)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Load subject: 1\n"
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'window_len'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-782f16330012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0msessions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mselected_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mselected_channels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0msegment_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-16-782f16330012>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, root, subject_ids, sessions, selected_channels, segment_config, verbose)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mdata_by_subjects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_by_subjects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mselected_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mselected_channels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0msegment_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-782f16330012>\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(data_by_subjects, selected_channels, segment_config)\u001b[0m\n\u001b[1;32m     43\u001b[0m             subject_data = segment_signal(\n\u001b[1;32m     44\u001b[0m                 \u001b[0msignal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubject_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mwindow_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                 \u001b[0mshift_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0msample_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'window_len'"
     ]
    }
   ],
   "source": [
    "def _load_multiple(root, dataset: PyTorchDataset, subject_ids: [], sessions: [], verbose: bool = False) -> None:\n",
    "    data_by_subjects = {}\n",
    "\n",
    "    for subject_id in subject_ids:\n",
    "        print('Load subject:', subject_id)\n",
    "        subject_data = None\n",
    "        subject_target = None\n",
    "\n",
    "        for session in sessions:\n",
    "            subject_dataset = dataset(root=root, subject_id=subject_id, session=session)\n",
    "\n",
    "            if subject_data is None: # if its session #1, will be None\n",
    "                subject_data = np.zeros((0, subject_dataset.data.shape[1], subject_dataset.data.shape[2]))\n",
    "                subject_target = np.zeros((0, ))\n",
    "\n",
    "            subject_data = np.concatenate((subject_data, subject_dataset.data))\n",
    "            subject_target = np.concatenate((subject_target, subject_dataset.targets))\n",
    "\n",
    "        subject_dataset_new = PyTorchDataset(data=subject_data, targets=subject_target)\n",
    "        subject_dataset_new.set_channel_names(subject_dataset.channel_names)\n",
    "        data_by_subjects[subject_id] = subject_dataset_new\n",
    "    \n",
    "    return data_by_subjects\n",
    "\n",
    "\n",
    "def _process_data(data_by_subjects, selected_channels, segment_config):\n",
    "\n",
    "    for subject_id in list(data_by_subjects.keys()):\n",
    "        subject_dataset = data_by_subjects[subject_id]\n",
    "\n",
    "        subject_data = subject_dataset.data\n",
    "        \n",
    "        # filter channels\n",
    "        if selected_channels is not None:\n",
    "            subject_data = pick_channels(\n",
    "                data=subject_data, \n",
    "                channel_names=subject_dataset.channel_names, \n",
    "                selected_channels=selected_channels\n",
    "            )\n",
    "\n",
    "        # selects the first segment (first 1-second), discard the rest\n",
    "        if segment_config is not None:\n",
    "            subject_data = segment_signal(\n",
    "                signal=subject_data,\n",
    "                window_len=segment_config.window_len,\n",
    "                shift_len=segment_config.shift_len,\n",
    "                sample_rate=segment_config.sample_rate,\n",
    "                add_segment_axis=segment_config.add_segment_axis,\n",
    "            )\n",
    "\n",
    "        subject_data_full = np.zeros((subject_data.shape[0], subject_data.shape[1], subject_data.shape[3]))\n",
    "\n",
    "        for trial in range(0, subject_data_full.shape[0]):\n",
    "            for channel in range(0, subject_data_full.shape[1]):\n",
    "                subject_data_full[trial, channel, :] = subject_data[trial, channel, 0, :]\n",
    "\n",
    "        subject_data = subject_data_full\n",
    "\n",
    "        # filter by bandpass\n",
    "        subject_data = butter_bandpass_filter(subject_data, lowcut=6, highcut=15, sample_rate=1000, order=6)\n",
    "\n",
    "        subject_dataset.set_data_targets(data=subject_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _train_test_dataset(data_by_subjects):\n",
    "    train_dataset_by_subjects = {}\n",
    "    test_dataset_by_subjects = {}\n",
    "\n",
    "    for subject_id in list(data_by_subjects.keys()):\n",
    "        train_dataset, test_dataset = train_test_split(data_by_subjects[subject_id].data, data_by_subjects[subject_id].targets)\n",
    "        \n",
    "        train_dataset_by_subjects[subject_id] = train_dataset\n",
    "        test_dataset_by_subjects[subject_id] = test_dataset\n",
    "    \n",
    "    return train_dataset_by_subjects, test_dataset_by_subjects\n",
    "\n",
    "\n",
    "\n",
    "class MultipleSubjects():\n",
    "\n",
    "    def __init__(self, \n",
    "        dataset: PyTorchDataset, \n",
    "        root: str, \n",
    "        subject_ids: [], \n",
    "        sessions: [], \n",
    "        selected_channels: [] = None,\n",
    "        segment_config: {} = None,\n",
    "        verbose: bool = False, \n",
    "    ) -> None:\n",
    "\n",
    "        self.data_by_subjects = _load_multiple(\n",
    "            root=root, \n",
    "            dataset=dataset, \n",
    "            subject_ids=subject_ids, \n",
    "            sessions=sessions\n",
    "        )\n",
    "\n",
    "        _process_data(\n",
    "            data_by_subjects=self.data_by_subjects, \n",
    "            selected_channels=selected_channels,\n",
    "            segment_config=segment_config,\n",
    "        )\n",
    "\n",
    "        self.train_dataset_by_subjects, \n",
    "        self.val_dataset_by_subjects = _train_test_dataset(self.data_by_subjects)\n",
    "\n",
    "    def leave_one_subject_out(self, selected_subject_id=1):\n",
    "\n",
    "        assert selected_subject_id in self.subjects_data, \"Must select subjects in dataset\"\n",
    "\n",
    "        # selected subject\n",
    "        selected_subject_x = self.data_by_subjects[selected_subject_id].data\n",
    "        selected_subject_y = self.data_by_subjects[selected_subject_id].targets\n",
    "        test_dataset = PyTorchDataset(selected_subject_x, selected_subject_y)\n",
    "\n",
    "        # the rest\n",
    "        other_subjects_x_train = []\n",
    "        other_subjects_y_train = []\n",
    "        other_subjects_x_val = []\n",
    "        other_subjects_y_val = []\n",
    "\n",
    "        for subject_id in list(self.data_by_subjects.keys()):\n",
    "            if subject_id != selected_subject_id:\n",
    "                other_subjects_x_train.extend(self.train_dataset_by_subjects[subject_id].data)\n",
    "                other_subjects_y_train.extend(self.train_dataset_by_subjects[subject_id].targets)\n",
    "\n",
    "                other_subjects_x_val.extend(self.val_dataset_by_subjects[subject_id].data)\n",
    "                other_subjects_y_val.extend(self.val_dataset_by_subjects[subject_id].targets)\n",
    "\n",
    "        other_subjects_x_train = np.array(other_subjects_x_train)\n",
    "        other_subjects_y_train = np.array(other_subjects_y_train)\n",
    "        other_subjects_x_val = np.array(other_subjects_x_val)\n",
    "        other_subjects_y_val = np.array(other_subjects_y_val)\n",
    "\n",
    "        train_dataset = PyTorchDataset(other_subjects_x_train, other_subjects_y_train)\n",
    "        val_dataset = PyTorchDataset(other_subjects_x_val, other_subjects_y_val)\n",
    "\n",
    "        return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "\n",
    "segment_config = {\n",
    "    'window_len':1,\n",
    "    'shift_len':1000,\n",
    "    'sample_rate':1000,\n",
    "    'add_segment_axis':True,\n",
    "}\n",
    "\n",
    "openbmi_data = MultipleSubjects(\n",
    "    dataset=OPENBMI, \n",
    "    root=root, \n",
    "    subject_ids=subject_ids, \n",
    "    sessions=sessions,\n",
    "    selected_channels=selected_channels,\n",
    "    segment_config=segment_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(25, 10, 1000)"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "openbmi_data.test_dataset_by_subjects[1].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594867990260",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}